{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       antecedents consequents   support  confidence      lift\n",
      "0         (Pastry)     (Bread)  0.029160    0.338650  1.034977\n",
      "1           (Cake)    (Coffee)  0.054728    0.526958  1.101515\n",
      "2        (Cookies)    (Coffee)  0.028209    0.518447  1.083723\n",
      "3  (Hot chocolate)    (Coffee)  0.029583    0.507246  1.060311\n",
      "4          (Juice)    (Coffee)  0.020602    0.534247  1.116750\n",
      "5      (Medialuna)    (Coffee)  0.035182    0.569231  1.189878\n",
      "6         (Pastry)    (Coffee)  0.047544    0.552147  1.154168\n",
      "7       (Sandwich)    (Coffee)  0.038246    0.532353  1.112792\n",
      "8            (Tea)    (Coffee)  0.049868    0.349630  0.730840\n",
      "9          (Toast)    (Coffee)  0.023666    0.704403  1.472431\n"
     ]
    }
   ],
   "source": [
    "#lp17 : Apriori\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Step 1: Data Preprocessing\n",
    "# Load the dataset\n",
    "df = pd.read_csv('./Datasets/Oder3.csv')\n",
    "\n",
    "# Generate transactions by grouping items by TransactionNo\n",
    "transactions = df.groupby('TransactionNo')['Items'].apply(list).tolist()\n",
    "\n",
    "# Step 2: Prepare the data for the Apriori algorithm\n",
    "# Convert transactions into a one-hot encoded format\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit_transform(transactions)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Step 3: Apply the Apriori Algorithm\n",
    "# Set minimum support to find frequent itemsets (example: 0.02)\n",
    "frequent_itemsets = apriori(df, min_support=0.02, use_colnames=True)\n",
    "# print(\"\\nFrequent Itemsets : \\n\",frequent_itemsets)\n",
    "\n",
    "# Step 4: Apply Association Rules\n",
    "# Apply the association rules with a minimum lift threshold of 1.\n",
    "# Remove num_itemsets=None if error comes here , it is due to version of mlxtend\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.30, num_itemsets=None)\n",
    "print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
